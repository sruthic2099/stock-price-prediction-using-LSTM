{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "pCB8bsEtUbLm",
    "outputId": "67e63976-4f9b-42fb-cdc9-bfa34e20b3dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFsN6f2OUcUm"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a31Er4DaUgha"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbHDwNz2U1XN"
   },
   "outputs": [],
   "source": [
    "def process(comp,n):\n",
    "    company=comp\n",
    "    s=datetime.date(2010,1,1)\n",
    "    e=datetime.date.today() - datetime.timedelta(1)\n",
    "    df = web.DataReader(company, data_source='yahoo', start=s, end=e)\n",
    "    fig = go.Figure(data=[go.Candlestick(x=df.index,\n",
    "                  open=df['Open'],\n",
    "                  high=df['High'],\n",
    "                  low=df['Low'],\n",
    "                  close=df['Close'],\n",
    "                  name='ohlc'                    )])\n",
    "    fig.update_layout(xaxis_rangeslider_visible=False,\n",
    "                      title=company,\n",
    "                      xaxis_title=\"Date\",\n",
    "                      yaxis_title=\"Price\",)\n",
    "    print(fig.show)\n",
    "    return fig,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8KlCX9RVFeb"
   },
   "outputs": [],
   "source": [
    "def closeT(df):\n",
    "    #Create a new dataframe with only the 'Close column\n",
    "    data = df.filter(['Close'])\n",
    "    print(data)\n",
    "    #Convert the dataframe to a numpy array\n",
    "    dataset = data.values\n",
    "    print(dataset)\n",
    "    #Get the number of rows to train the model on\n",
    "    training_data_len = math.ceil( len(dataset) * .8 )\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    #Create the training data set\n",
    "    #Create the scaled training data set\n",
    "    train_data = scaled_data[0:training_data_len , :]\n",
    "    #Split the data into x_train and y_train data sets\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(60, len(train_data)):\n",
    "      x_train.append(train_data[i-60:i, 0])\n",
    "      y_train.append(train_data[i, 0])\n",
    "      if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "    #Convert the x_train and y_train to numpy arrays \n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    \n",
    "    #Reshape the data\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    \n",
    "    #Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "    model.add(LSTM(50, return_sequences= False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    if (not os.path.exists(f'stock_prediction-{ticker}.h5')):\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "        model.save(f'stock_prediction-{ticker}.h5')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8KlCX9RVFeb"
   },
   "outputs": [],
   "source": [
    "def closeT(company,df):\n",
    "    from keras.models import load_model\n",
    "    from keras import backend as K\n",
    "    #Create a new dataframe with only the 'Close column\n",
    "    data = df.filter(['Close'])\n",
    "    #print(data)\n",
    "    \n",
    "    #Convert the dataframe to a numpy array\n",
    "    dataset = data.values\n",
    "    #print(dataset)\n",
    "    \n",
    "    #Get the number of rows to train the model on\n",
    "    training_data_len = math.ceil( len(dataset) * .8 )\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    \n",
    "    #Create the training data set\n",
    "    #Create the scaled training data set\n",
    "    train_data = scaled_data[0:training_data_len , :]\n",
    "    \n",
    "    #Split the data into x_train and y_train data sets\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(60, len(train_data)):\n",
    "      x_train.append(train_data[i-60:i, 0])\n",
    "      y_train.append(train_data[i, 0])\n",
    "      if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "    #Convert the x_train and y_train to numpy arrays \n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    #Reshape the data\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    \n",
    "    #Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "    model.add(LSTM(50, return_sequences= False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    if (not os.path.exists(f'stock_prediction-{company}.h5')):\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "        model.save(f'stock_prediction-{company}.h5')\n",
    "        \n",
    "    #Create the testing data set\n",
    "    test_data = scaled_data[training_data_len - 60: , :]\n",
    "    #Create the data sets x_test and y_test\n",
    "    x_test = []\n",
    "    y_test = dataset[training_data_len:, :]\n",
    "    for i in range(60, len(test_data)):\n",
    "        x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "    #Convert the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "    \n",
    "    #Reshape the data\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "    #Get the models predicted price values \n",
    "    K.clear_session()\n",
    "    model1 = load_model(f'stock_prediction-{company}.h5')\n",
    "    predictions = model1.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    #Get the root mean squared error (RMSE)\n",
    "    rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
    "    print(rmse)#Plot the data\n",
    "    train = data[:training_data_len]\n",
    "    valid = data[training_data_len:]\n",
    "    valid['Predictions'] = predictions\n",
    "    \n",
    "    #Visualize the data\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create and style traces\n",
    "    fig.add_trace(go.Scatter(x=df.index,y=df['Close'], name='close' ))\n",
    "    fig.add_trace(go.Scatter(x=valid.index,y=valid['Predictions'],name='Close Predictions'))\n",
    "    #print(fig.show)\n",
    "    #print(valid)\n",
    "    return valid,fig,scaler,model1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAlP85h6VLLO"
   },
   "outputs": [],
   "source": [
    "def predict(company,n,scaler,model):\n",
    "            e=datetime.date.today()\n",
    "            apple_quote = web.DataReader(company, data_source='yahoo', start='2015-01-01', end=e)\n",
    "\n",
    "            #Create a new dataframe\n",
    "            apple_quote.reset_index(inplace=True)\n",
    "            \n",
    "            #print(apple_quote)\n",
    "            new_df  = pd.DataFrame(apple_quote[['Date','Close']])\n",
    "            #print(new_df)\n",
    "            #Get teh last 60 day closing price values and convert the dataframe to an array\n",
    "            \n",
    "            for z in range(0,n):\n",
    "                new_df1=new_df.filter(['Close'])\n",
    "                tomorrow=new_df['Date'].tail(1)\n",
    "                #print(tomorrow)\n",
    "                \n",
    "                for date in tomorrow:\n",
    "                    d1=date\n",
    "\n",
    "                #print(tomorrow)\n",
    "                #print(d1)\n",
    "                if(d1.weekday()==4):\n",
    "                    dd=3;\n",
    "                else:\n",
    "                    dd=1;\n",
    "                last_60_days = new_df1[-60:].values\n",
    "                #print(\"last_60_days\",last_60_days)\n",
    "            \n",
    "                    #Scale the data to be values between 0 and 1\n",
    "                last_60_days_scaled = scaler.transform(last_60_days)\n",
    "                    #Create an empty list\n",
    "                X_test = []\n",
    "                    #Append teh past 60 days\n",
    "                X_test.append(last_60_days_scaled)\n",
    "                    #Convert the X_test data set to a numpy array\n",
    "                X_test = np.array(X_test)\n",
    "                    #Reshape the data\n",
    "                X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "                    #Get the predicted scaled price\n",
    "                pred_price = model.predict(X_test)\n",
    "                    #undo the scaling \n",
    "                pred_price = scaler.inverse_transform(pred_price)\n",
    "                #print(pred_price)\n",
    "            \n",
    "                for i in pred_price:\n",
    "                    price=i\n",
    "                    for j in i:\n",
    "                        p1=j\n",
    "\n",
    "                        new_row = {\"Date\":d1 + datetime.timedelta(days=dd),\"Close\":p1}\n",
    "                        new_df=new_df.append(new_row,ignore_index=True)\n",
    "                new_df2=new_df.tail(n)\n",
    "                #print(new_df)\n",
    "            \n",
    "            fig = px.line(new_df, x='Date', y='Close')\n",
    "            #print(fig.show)\n",
    "            return new_df2,fig\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "MdgG619wvdtW",
    "outputId": "a5061a81-7dd7-4886-9e81-9f33d69f8c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [23/Jun/2020 13:13:47] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:13:47] \"\u001b[33mGET /static/images/logo.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:13:57] \"\u001b[37mGET /predict.html HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:13:57] \"\u001b[33mGET /static/images/logo.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:13:57] \"\u001b[33mGET /static/images/Searchs_002.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:13:59] \"\u001b[37mGET /proof.html HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:14:00] \"\u001b[33mGET /static/images/logo.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [23/Jun/2020 13:14:00] \"\u001b[33mGET /static/images/logo.png HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from plotly.offline import plot\n",
    "import json\n",
    "import plotly\n",
    "from flask import Flask, flash, redirect, render_template, request, url_for,session\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def forms():\n",
    "    return render_template('/index.html')\n",
    "\n",
    "@app.route('/index.html')\n",
    "def index():\n",
    "    return render_template('/index.html')\n",
    "\n",
    "@app.route('/predict.html')\n",
    "def cindex():\n",
    "    return render_template('/predict.html')\n",
    "\n",
    "@app.route('/proof.html')\n",
    "def pindex():\n",
    "    return render_template('proof.html')\n",
    "\n",
    "\n",
    "@app.route('/result.html', methods = ['POST', 'GET'])\n",
    "def result():\n",
    "    \n",
    "    #if request.method == 'POST':\n",
    "            company=request.form[\"company\"] \n",
    "            n1=request.form[\"period\"] \n",
    "            n=int(n1)\n",
    "            fig,df=process(company,n)\n",
    "            df1=df.tail(92)\n",
    "            fig_json = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "            valid,fig1,scaler,model=closeT(company,df)\n",
    "            \n",
    "            fig_json1 = json.dumps(fig1, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "            new_df2,fig2=predict(company,n,scaler,model)\n",
    "            fig_json2 = json.dumps(fig2, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "            return render_template(\"/result.html\",comp=company,period=n,table_df=[df1.to_html(table_id=\"myTable\",classes=None,border=0,header=\"true\")],tables=[new_df2.to_html(header=\"true\",table_id=\"myTable1\",border=0,index=False)],plot=fig_json,plot1=fig_json1,plot2=fig_json2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug = True,use_reloader=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stockFinal.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
